{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Spark Moive Recommendation\n",
        "In this notebook, Alternating Least Squares (ALS) algorithm will be used with Spark APIs to predict the ratings for the movies in [MovieLens small dataset](https://grouplens.org/datasets/movielens/latest/)"
      ],
      "metadata": {
        "id": "KbDHl75NIsK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "%matplotlib inline\n",
        "\n",
        "!pip install pyspark\n",
        "!pip install mlflow\n",
        "#dbutils.library.installPyPI(\"mlflow\")\n",
        "#dbutils.library.restartPython()\n",
        "import mlflow"
      ],
      "metadata": {
        "collapsed": true,
        "id": "R-GO29ebIsK4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PYSPARK_PYTHON\"] = \"python3\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "_HGwMAkOIsK6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part1: Data ETL and Data Exploration"
      ],
      "metadata": {
        "id": "j88DHAA-IsK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"moive analysis\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QKK-QYTkIsK7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive');\n",
        "DATA_PATH = \"drive/My Drive/Big Data Project/Data/MovieLens27M/\""
      ],
      "metadata": {
        "id": "PRVf-eL2JRcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df = spark.read.load(DATA_PATH + \"movies.csv\", format='csv', header = True)\n",
        "ratings_df = spark.read.load(DATA_PATH + \"ratings.csv\", format='csv', header = True)\n",
        "links_df = spark.read.load(DATA_PATH + \"links.csv\", format='csv', header = True)\n",
        "tags_df = spark.read.load(DATA_PATH + \"tags.csv\", format='csv', header = True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fZJMvzJJIsK7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "type(movies_df)"
      ],
      "metadata": {
        "id": "nFBpUVEDIsK8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.count()"
      ],
      "metadata": {
        "id": "tovgfLJCIsK8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#movies_df.show(5)\n",
        "\n",
        "movies_df.createOrReplaceTempView(\"movies_df\")\n",
        "\n",
        "display (spark.sql(\"SELECT * FROM movies_df limit 5\"))"
      ],
      "metadata": {
        "id": "WNXxDsjaIsK8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#ratings_df.show(5)\n",
        "\n",
        "ratings_df.createOrReplaceTempView(\"ratings_df\")\n",
        "\n",
        "display (spark.sql(\"SELECT * FROM ratings_df limit 5\"))"
      ],
      "metadata": {
        "id": "kEXk_TVBIsK9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "links_df.show(5)\n",
        "\n",
        "links_df.createOrReplaceTempView(\"links_df\")\n",
        "\n",
        "display (spark.sql(\"SELECT * FROM links_df limit 5\"))"
      ],
      "metadata": {
        "id": "uhZu7WStIsK9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#tags_df.show(5)\n",
        "\n",
        "tags_df.createOrReplaceTempView(\"tags_df\")\n",
        "\n",
        "display (spark.sql(\"SELECT * FROM tags_df limit 5\"))"
      ],
      "metadata": {
        "id": "FC_OiVvEIsK-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tmp1 = ratings_df.groupBy(\"userID\").count().toPandas()['count'].min()\n",
        "tmp2 = ratings_df.groupBy(\"movieId\").count().toPandas()['count'].min()\n",
        "print('For the users that rated movies and the movies that were rated:')\n",
        "print('Minimum number of ratings per user is {}'.format(tmp1))\n",
        "print('Minimum number of ratings per movie is {}'.format(tmp2))"
      ],
      "metadata": {
        "id": "ytEBw1etIsK_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tmp1 = sum(ratings_df.groupBy(\"movieId\").count().toPandas()['count'] == 1)\n",
        "tmp2 = ratings_df.select('movieId').distinct().count()\n",
        "print('{} out of {} movies are rated by only one user'.format(tmp1, tmp2))"
      ],
      "metadata": {
        "id": "En4ApvYlIsLA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Spark SQL and OLAP"
      ],
      "metadata": {
        "id": "Qw3dmRICIsLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.registerTempTable(\"movies\")\n",
        "ratings_df.registerTempTable(\"ratings\")\n",
        "links_df.registerTempTable(\"links\")\n",
        "tags_df.registerTempTable(\"tags\")"
      ],
      "metadata": {
        "id": "Gc1sq3xeIsLB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1: The number of Users"
      ],
      "metadata": {
        "id": "DxzIgU0wIsLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %sql\n",
        "num_users = spark.sql(\"SELECT count (distinct userID) as num_users FROM ratings\")\n",
        "display(num_users)"
      ],
      "metadata": {
        "id": "Wd56Y_TRIsLB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df.select(\"userId\").distinct().count()"
      ],
      "metadata": {
        "id": "7sXBwnhzIsLC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "type(ratings_df.select(\"userId\"))"
      ],
      "metadata": {
        "id": "aSm4nCgwIsLC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2: The number of Movies"
      ],
      "metadata": {
        "id": "0lgzHfPmIsLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%sql \n",
        "num_movies = spark.sql(\"SELECT count (distinct movieID) as num_movies FROM movies\")\n",
        "display(num_movies)"
      ],
      "metadata": {
        "id": "JIaze2iUIsLD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.select('movieID').distinct().count()"
      ],
      "metadata": {
        "id": "d4Kp0crzIsLD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.select('movieID').count()"
      ],
      "metadata": {
        "id": "AOKLoDA5IsLD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3:  How many movies are rated by users? List movies not rated before"
      ],
      "metadata": {
        "id": "IKGptyZ9IsLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rated_by_users = ratings_df.select('movieID').distinct().count()\n",
        "print('How many movies are rated by users?', rated_by_users)"
      ],
      "metadata": {
        "id": "dfax6X5MIsLE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%sql \n",
        "SELECT movies.title, movies.genres, ratings.rating FROM movies left JOIN ratings ON ratings.movieId = movies.movieID WHERE ratings.rating IS null LIMIT 10"
      ],
      "metadata": {
        "id": "Jl0rcTfHIsLE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4: List Movie Genres"
      ],
      "metadata": {
        "id": "1jk9n3wuIsLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%sql\n",
        "SELECT DISTINCT(genres) FROM movies LIMIT 10"
      ],
      "metadata": {
        "id": "USaCC-_kIsLF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%sql\n",
        "SELECT SUBSTRING_INDEX(SUBSTRING_INDEX(genres, '|', 1), '|', -1) as genre FROM movies\n",
        "UNION\n",
        "SELECT  SUBSTRING_INDEX(SUBSTRING_INDEX(genres, '|', 2), '|', -1) as genre FROM movies\n",
        "UNION\n",
        "SELECT  SUBSTRING_INDEX(SUBSTRING_INDEX(genres, '|', 3), '|', -1) as genre FROM movies\n",
        "UNION\n",
        "SELECT  SUBSTRING_INDEX(SUBSTRING_INDEX(genres, '|', 4), '|', -1) as genre FROM movies\n",
        "UNION\n",
        "SELECT  SUBSTRING_INDEX(SUBSTRING_INDEX(genres, '|', 5), '|', -1) as genre FROM movies\n",
        "UNION\n",
        "SELECT  SUBSTRING_INDEX(SUBSTRING_INDEX(genres, '|', 6), '|', -1) as genre FROM movies\n",
        "ORDER BY genre;\n",
        "\n",
        "--This is method I do not like"
      ],
      "metadata": {
        "id": "7PbTV6LEIsLF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import col, mean, udf, lit, current_timestamp, unix_timestamp, array_contains\n",
        "extract_genres = udf(lambda x: x.split(\"|\"), ArrayType(StringType()))\n",
        "movies_df_clean = movies_df.select(\"movieId\", \"title\", extract_genres(\"genres\").alias(\"genres\"))\n",
        "#display(movies_df_clean)\n",
        "\n",
        "movies_df_clean.createOrReplaceTempView(\"movies_df_clean\")\n",
        "\n",
        "display (spark.sql(\"SELECT * FROM movies_df_clean limit 5\"))"
      ],
      "metadata": {
        "id": "gGATBy16IsLF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "genres_result = list(set(movies_df_clean.select('genres').rdd.flatMap(tuple).flatMap(tuple).collect()))\n",
        "genres_result"
      ],
      "metadata": {
        "id": "2gmG0xEkIsLG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5: Movie for Each Category"
      ],
      "metadata": {
        "id": "QahK-64HIsLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genres_result = list(set(movies_df_clean.select('genres').rdd.flatMap(tuple).flatMap(tuple).collect()))\n",
        "genres_result"
      ],
      "metadata": {
        "id": "usVyKMdQIsLG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "movie_pdf = movies_df.toPandas()\n",
        "movie_pdf['genres'].str.get_dummies(sep='|').head()"
      ],
      "metadata": {
        "id": "tZSbrRZMIsLH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_movie = list(movie_pdf['title'])"
      ],
      "metadata": {
        "id": "57i0nbRZIsLH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part2: Spark ALS based approach for training model\n",
        "We will use an Spark ML to predict the ratings, so let's reload \"ratings.csv\" using ``sc.textFile`` and then convert it to the form of (user, item, rating) tuples."
      ],
      "metadata": {
        "id": "T1a7TgtRIsLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ratings_df.show(10)\n",
        "\n",
        "ratings_df.createOrReplaceTempView(\"ratings_df\")\n",
        "\n",
        "display (spark.sql(\"SELECT * FROM ratings_df limit 5\"))"
      ],
      "metadata": {
        "id": "-O_S8tyeIsLI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "movie_ratings=ratings_df.drop('timestamp')"
      ],
      "metadata": {
        "id": "hh5pE1OKIsLI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Data type convert\n",
        "from pyspark.sql.types import IntegerType, FloatType\n",
        "movie_ratings = movie_ratings.withColumn(\"userId\", movie_ratings[\"userId\"].cast(IntegerType()))\n",
        "movie_ratings = movie_ratings.withColumn(\"movieId\", movie_ratings[\"movieId\"].cast(IntegerType()))\n",
        "movie_ratings = movie_ratings.withColumn(\"rating\", movie_ratings[\"rating\"].cast(FloatType()))"
      ],
      "metadata": {
        "id": "R_gBUzB6IsLI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#movie_ratings.show(10)\n",
        "\n",
        "movie_ratings.createOrReplaceTempView(\"movie_ratings\")\n",
        "\n",
        "display (spark.sql(\"SELECT * FROM movie_ratings limit 10\"))"
      ],
      "metadata": {
        "id": "mtZ1CdlMIsLJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ALS Model Selection and Evaluation\n",
        "\n",
        "With the ALS model, we can use a grid search to find the optimal hyperparameters."
      ],
      "metadata": {
        "id": "Sye9UbPCIsLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import package\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder"
      ],
      "metadata": {
        "id": "BnJEFHKGIsLJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Create test and train set\n",
        "(training,test)=movie_ratings.randomSplit([0.8,0.2])"
      ],
      "metadata": {
        "id": "wlveuCj7IsLK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ALS model\n",
        "# Build the recommendation model using ALS on the training data\n",
        "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
        "als = ALS(maxIter=5, rank=10, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
        "          coldStartStrategy=\"drop\")"
      ],
      "metadata": {
        "id": "-sz0RPXJIsLK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 1st print a list of parameters\n",
        "print(als.explainParams())"
      ],
      "metadata": {
        "id": "fT7aNsrwIsLK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Tune model using ParamGridBuilder\n",
        "# it will take long time in the cv period, so just use few parameter to try \n",
        "\n",
        "paramGrid = (ParamGridBuilder()\n",
        "             .addGrid(als.regParam, [0.01])\n",
        "             .addGrid(als.rank, [10])\n",
        "             .addGrid(als.maxIter, [15])\n",
        "             .build())\n",
        "\n",
        "# paramGrid = (ParamGridBuilder()\n",
        "#              .addGrid(als.regParam, [0.01, 0.5, 1, 1.5])\n",
        "#              .addGrid(als.rank, [10, 15, 20, 25])\n",
        "#              .addGrid(als.maxIter, [1, 5, 10, 15])\n",
        "#              .build())"
      ],
      "metadata": {
        "id": "weFpjrdsIsLK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define evaluator as RMSE\n",
        "\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
        "                                predictionCol=\"prediction\")"
      ],
      "metadata": {
        "id": "w18pnjFmIsLL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import CrossValidator\n",
        "# Build Cross validation \n",
        "# Create 5-fold CrossValidator\n",
        "# it takes too long that I only use 2-fold\n",
        "cv = CrossValidator(estimator=als, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=2)\n",
        "\n",
        "# Run cross validations\n",
        "cvModel = cv.fit(training)\n",
        "# this will likely take a fair amount of time because of the amount of models that we're creating and testing"
      ],
      "metadata": {
        "id": "_K13gvwkIsLL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the best model selected by CV\n",
        "best_model = cvModel.bestModel"
      ],
      "metadata": {
        "id": "_oFDPWObIsLL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit ALS model to training data\n",
        "\n",
        "# specify parameter settings by the best model obtained via CV\n",
        "print (\"**Best Model**\")\n",
        "print (\"Rank: \", best_model)\n",
        "print (\" MaxIter: \", str(best_model._java_obj.parent().getMaxIter()))\n",
        "print (\" RegParam:\",  best_model._java_obj.parent().regParam())"
      ],
      "metadata": {
        "id": "C56IcU7KIsLM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model testing\n",
        "And finally, make a prediction and check the testing error."
      ],
      "metadata": {
        "id": "pd3hvWJmIsLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate predictions and evaluate using RMSE\n",
        "predictions=best_model.transform(test)\n",
        "rmse = evaluator.evaluate(predictions)"
      ],
      "metadata": {
        "id": "i7bsYnfrIsLM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Print RMSE \n",
        "print (\"RMSE = \"+str(rmse))"
      ],
      "metadata": {
        "id": "nPvQj-9-IsLM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract best model from the tuning exercise using ParamGridBuilder\n",
        "\n",
        "als_best = ALS(maxIter=15, rank=10, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
        "          coldStartStrategy=\"drop\")\n",
        "model = als_best.fit(training)"
      ],
      "metadata": {
        "id": "eUZN7_KUIsLN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions.show(10)\n",
        "\n",
        "predictions.createOrReplaceTempView(\"predictions\")\n",
        "\n",
        "display (spark.sql(\"SELECT * FROM predictions limit 10\"))"
      ],
      "metadata": {
        "id": "nehsSSGYIsLN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model apply and see the performance"
      ],
      "metadata": {
        "id": "ag3_LOovIsLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alldata=best_model.transform(movie_ratings)\n",
        "rmse = evaluator.evaluate(alldata)\n",
        "print (\"RMSE = \"+str(rmse))"
      ],
      "metadata": {
        "id": "VlrGy5NbIsLO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "alldata.registerTempTable(\"alldata\")"
      ],
      "metadata": {
        "id": "ySc5h7Q5IsLO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%sql SELECT * FROM alldata LIMIT 10"
      ],
      "metadata": {
        "id": "HICJOpFHIsLP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%sql SELECT * FROM movies JOIN alldata ON movies.movieId=alldata.movieId LIMIT 10"
      ],
      "metadata": {
        "id": "z5WIvZEPIsLP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommend moive to users with id: 575, 232. \n",
        "you can choose some users to recommend the moives"
      ],
      "metadata": {
        "id": "CBefBdjyIsLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#recommend 10 movies for each users\n",
        "user_recs = best_model.recommendForAllUsers(10)\n",
        "#user_recs.show(10)\n",
        "\n",
        "user_recs.createOrReplaceTempView(\"user_recs\")\n",
        "\n",
        "display (spark.sql(\"SELECT * FROM user_recs limit 10\"))"
      ],
      "metadata": {
        "id": "tqLlqi11IsLP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "user_recs.first()"
      ],
      "metadata": {
        "id": "a7zjeBxwIsLQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "user_recs.registerTempTable(\"als_recs_temp\")"
      ],
      "metadata": {
        "id": "XYGufW_CIsLQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# seperate the value of 'recommendations' in user_recs\n",
        "\n",
        "explode_rec = spark.sql('SELECT userId,\\\n",
        "                                explode(recommendations) AS MovieRec\\\n",
        "                                FROM als_recs_temp')\n",
        "#explode_rec.show(10)\n",
        "\n",
        "\n",
        "explode_rec.createOrReplaceTempView(\"explode_rec\")\n",
        "\n",
        "display (spark.sql(\"SELECT * FROM explode_rec limit 10\"))"
      ],
      "metadata": {
        "id": "h_xetLKSIsLR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "fianl_recs = spark.sql(\"SELECT userId,\\\n",
        "                               movieIds_and_ratings.movieId AS movieId,\\\n",
        "                               movieIds_and_ratings.rating AS prediction\\\n",
        "                               FROM als_recs_temp\\\n",
        "                               LATERAL VIEW explode(recommendations) exploded_table AS movieIds_and_ratings\")"
      ],
      "metadata": {
        "id": "4dnUrm3aIsLR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#fianl_recs.show(10)\n",
        "\n",
        "\n",
        "fianl_recs.createOrReplaceTempView(\"fianl_recs\")\n",
        "\n",
        "display (spark.sql(\"SELECT * FROM fianl_recs limit 10\"))"
      ],
      "metadata": {
        "id": "cL4ZcgOOIsLR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Before we recommend the films, we need to filter out those users have not seen yet. Therefore, we need to choose rating = 'null' by join the movie ratings\n",
        "\n",
        "final_rec = fianl_recs.join(movie_ratings,['userId','movieId'],'left').filter(movie_ratings.rating.isNull())\n",
        "#display(final_rec)\n",
        "\n",
        "final_rec.createOrReplaceTempView(\"final_rec\")\n",
        "\n",
        "display (spark.sql(\"SELECT * FROM final_rec LIMIT 5\"))"
      ],
      "metadata": {
        "id": "WRV2MQWjIsLS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "final_rec.registerTempTable(\"final_rec\")\n",
        "movies_df.registerTempTable(\"movies_df\")"
      ],
      "metadata": {
        "id": "J9uZGMhkIsLS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find recommend films for userid = 575"
      ],
      "metadata": {
        "id": "Gratk8rCIsLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%sql\n",
        "SELECT userId,\n",
        "       title\n",
        "FROM final_rec t1\n",
        "LEFT JOIN movies_df t2\n",
        "ON t1.movieId = t2.movieId\n",
        "WHERE t1.userId=575\n",
        "LIMIT 10"
      ],
      "metadata": {
        "id": "v3Buz3bCIsLT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find recommend films for userid = 273"
      ],
      "metadata": {
        "id": "wv6-LNx2IsLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%sql\n",
        "SELECT userId,\n",
        "       title\n",
        "FROM final_rec t1\n",
        "LEFT JOIN movies_df t2\n",
        "ON t1.movieId = t2.movieId\n",
        "WHERE t1.userId=273\n",
        "LIMIT 5"
      ],
      "metadata": {
        "id": "ESCkWboXIsLT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find the similar moives for moive with id: 463, 471\n",
        "You can find the similar moives based on the ALS results"
      ],
      "metadata": {
        "id": "Vf4DaOqtIsLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1st extract productFeatures matrix\n",
        "# The productFeatures matrix will be used to create an item-item collaborative filtering recommendation model\n",
        "from pyspark.mllib.recommendation import ALS\n",
        "import math\n",
        "\n",
        "model_a = ALS.train(movie_ratings, rank=10, iterations=15,\n",
        "                      lambda_=0.01)\n",
        "model_a.productFeatures().count()"
      ],
      "metadata": {
        "id": "pCMA98qiIsLT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# look at the feature vector of movie 463\n",
        "movie_feature = model_a.productFeatures().lookup(471)[0]"
      ],
      "metadata": {
        "id": "TsWPID7pIsLU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Next define cosine similarity function to measure movie similarity\n",
        "def cosineSimilarity(vec1, vec2):\n",
        "  return vec1.dot(vec2) / (LA.norm(vec1) * LA.norm(vec2))"
      ],
      "metadata": {
        "id": "tTxIXPNVIsLU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigns the movies title file\n",
        "movies_file = os.path.join(\"/FileStore/tables/\", 'movies.csv')\n",
        "movies_sc = sc.textFile(movies_file)\n",
        "\n",
        "movies_sc_header = movies_sc.take(1)[0]\n",
        "\n",
        "movies_data = movies_sc.filter(lambda line: line!=movies_sc_header)\\\n",
        "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1])).cache()\n",
        "\n",
        "movies_titles = movies_data.map(lambda x: (int(x[0]),x[1]))"
      ],
      "metadata": {
        "id": "EoAEoaeWIsLU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "movies_sc_header"
      ],
      "metadata": {
        "id": "LVOWUWAbIsLU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "movies_data"
      ],
      "metadata": {
        "id": "lr2IcqlSIsLV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "movies_titles"
      ],
      "metadata": {
        "id": "5KaRJ7o9IsLV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Build similarity matrix for movieid 471 using the product features matrix\n",
        "\n",
        "similarMovies = model_a.productFeatures().map(lambda products:(products[0],\n",
        "                                        cosineSimilarity(np.asarray(products[1]), movie_feature))).join(movies_titles).map(lambda r: (r[1][1], r[1][0], r[0]))\n",
        "\n",
        "# Sort the top 10 most similar movies descendingly by cosine similarity measure\n",
        "# similarMovies.takeOrdered(11, key=lambda x: -x[1])"
      ],
      "metadata": {
        "id": "w0hkxHBNIsLV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
        "from pyspark.ml.linalg import Vectors, VectorUDT"
      ],
      "metadata": {
        "id": "i-zgZCORIsLW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "a = best_model.itemFactors\n",
        "# display(a.cache())\n",
        "\n",
        "a.createOrReplaceTempView(\"a\")\n",
        "\n",
        "display (spark.sql(\"SELECT * FROM a limit 5\"))"
      ],
      "metadata": {
        "id": "i-PRs9AbIsLW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "a.registerTempTable(\"movie_on_movie\")"
      ],
      "metadata": {
        "id": "o2ODsDnNIsLW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%sql\n",
        "SELECT features FROM movie_on_movie WHERE id = 471"
      ],
      "metadata": {
        "id": "Nj8Y2GjOIsLW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%sql\n",
        "SELECT * FROM ratings WHERE movieId = 463 LIMIT 10"
      ],
      "metadata": {
        "id": "T-mMX87MIsLX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "brp = BucketedRandomProjectionLSH(inputCol=\"features\", outputCol=\"hashes\",seed=12345, bucketLength=1.0)\n",
        "#a.printSchema()\n",
        "#change features columns into dense vector\n",
        "to_vector = udf(lambda a: Vectors.dense(a), VectorUDT())\n",
        "data = a.select(\"id\", to_vector(\"features\").alias(\"features\"))\n",
        "#data.printSchema()"
      ],
      "metadata": {
        "id": "EdDtJPvVIsLX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = brp.fit(data)\n",
        "model.transform(data)"
      ],
      "metadata": {
        "id": "5TNOC_6JIsLX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.approxNearestNeighbors(data, Vectors.dense([-0.73946416, -1.03179, -0.83905196, -0.6525196, -0.3816911, -0.88358724, -0.47698575, -0.15836999, 0.36126232, -0.6475737]), 6).collect()"
      ],
      "metadata": {
        "id": "F2l8HDm6IsLY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# similar moives for moive with id: 471"
      ],
      "metadata": {
        "id": "snkonIuoIsLY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%sql\n",
        "SELECT * FROM movies\n",
        "WHERE movieId IN (6296,97057,3476,1059,4346)"
      ],
      "metadata": {
        "id": "OAZjPN3yIsLY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%sql\n",
        "SELECT features FROM movie_on_movie WHERE id = 463"
      ],
      "metadata": {
        "id": "3dMRMUaKIsLY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.approxNearestNeighbors(data, Vectors.dense([0.93929714, 0.015614069, -0.3408886, 0.3818301, 0.19762212, -1.4255825, 0.99496984, -0.065754086, 0.43202916, -0.8621043]), 6).collect()"
      ],
      "metadata": {
        "id": "f-pFfID4IsLZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# similar moives for moive with id: 463"
      ],
      "metadata": {
        "id": "97BGPUCWIsLZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%sql\n",
        "SELECT * FROM movies\n",
        "WHERE movieId IN (5321,49007,554,7276,7224)"
      ],
      "metadata": {
        "id": "d-H9fDcvIsLZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the above, we obtain the 5 movies that are most similar to movie with id: 471. They are:\n",
        "William Shakespeare's Romeo + Juliet (1996),\n",
        "\"Jacob's Ladder (1990)',\n",
        "'Bride of the Wind (2001)',\n",
        "'Stop Making Sense (1984)',\n",
        "'Mighty Wind, A (2003)',\n",
        "'Kon-Tiki (2012)'."
      ],
      "metadata": {
        "id": "y859l9SWIsLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Report \n",
        "### Motivation: \n",
        "I dig deep into ALS collaberative recommendation engine by using Spark MLlib and give recommendation with user based movie recommendation with a scalable matrix factorization technique.\n",
        "\n",
        "### Step1\n",
        "\n",
        "First I load four of datasets, namely movie, rating, links and tags and conduct a number of data explorations on these data to get some basic information, such as number of users, number of movies, number of ratings per users and per movies respectively, and distribution of movies on different genres.\n",
        "\n",
        "### Step2\n",
        "\n",
        "After doing data preprocessings, I build an ALS model based on the rating data to predict the ratings, which is treated as degree of preference of movies among different users. The parameters (maxIter, rank, regParam) are tuned by grid search strategy via 5-fold cross validation to obtain the model with the smallest RMSE on the validation set. This is considered to be the best model for prediction.\n",
        "\n",
        "### Step3\n",
        "\n",
        "By the best model obtained from the above step, making predictions of ratings on movies in the test set and calculating the RMSE to evaluate the model performance  are preparing for the next step.\n",
        "\n",
        "### Step4  \n",
        "\n",
        "In this step, I use the prediction results by the best model to recommend 5 movies for userID 575 and 232 respectively; and we also find 5 movies that are the most similar to movie with movieID 471 and 463 by the approximate nearest neighbor search algorithm on the movie feature vector.\n",
        "\n",
        "### Conclusion\n",
        "The RMSE of the best ALS model on the test data is 0.71, indicating the model is with good performance in predicting the ratings for movies; ALS model is able to provide both recommendations of movies based on user's preferences and also similar movies to a specific movie, which shows its effectiveness as one of most critical techniques in recommendation system. More works can be considered to further improve the model performance, such as making use of information from other data sets such as genres of movies and tag information, building ALS model incorporatng both explicit and implicit feedbacks, and try some other techniques such as KNN, Deep Learning, applying ensemble based on several methods, and so on."
      ],
      "metadata": {
        "id": "kpp6I6SHIsLa"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "name": "python",
      "pygments_lexer": "ipython2",
      "codemirror_mode": {
        "name": "ipython",
        "version": "2"
      },
      "version": "2.7.14",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "name": "Movie Recommendation Engine in Apache Spark",
    "notebookId": 2964997303881322,
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DxzIgU0wIsLB",
        "0lgzHfPmIsLC",
        "IKGptyZ9IsLE",
        "1jk9n3wuIsLE",
        "QahK-64HIsLG",
        "T1a7TgtRIsLI",
        "Sye9UbPCIsLJ",
        "pd3hvWJmIsLM",
        "ag3_LOovIsLO",
        "CBefBdjyIsLP",
        "Gratk8rCIsLS",
        "wv6-LNx2IsLT",
        "Vf4DaOqtIsLT",
        "kpp6I6SHIsLa"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}